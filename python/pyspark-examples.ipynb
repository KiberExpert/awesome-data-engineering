{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from pyspark.sql import SparkSession\nfrom pyspark import SparkContext","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T08:17:50.740685Z","iopub.execute_input":"2025-05-13T08:17:50.741361Z","iopub.status.idle":"2025-05-13T08:17:50.751050Z","shell.execute_reply.started":"2025-05-13T08:17:50.741190Z","shell.execute_reply":"2025-05-13T08:17:50.749474Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"spark=SparkSession.builder.appName(name='Pyspark examples').getOrCreate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T06:56:20.020003Z","iopub.execute_input":"2025-05-13T06:56:20.020525Z","iopub.status.idle":"2025-05-13T06:56:29.105632Z","shell.execute_reply.started":"2025-05-13T06:56:20.020469Z","shell.execute_reply":"2025-05-13T06:56:29.103999Z"}},"outputs":[{"name":"stderr","text":"Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n25/05/13 06:56:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# DataFrame’dan faqat `name` va `age` ustunlarini tanlang\n\ndf = spark.createDataFrame([(\"Ali\", 25), (\"Vali\", 30)], [\"name\", \"age\"])\n\ndf.select('name', 'age').show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T06:56:29.109227Z","iopub.execute_input":"2025-05-13T06:56:29.109730Z","iopub.status.idle":"2025-05-13T06:56:39.089217Z","shell.execute_reply.started":"2025-05-13T06:56:29.109698Z","shell.execute_reply":"2025-05-13T06:56:39.087360Z"}},"outputs":[{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"+----+---+\n|name|age|\n+----+---+\n| Ali| 25|\n|Vali| 30|\n+----+---+\n\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Faqat `age > 25` bo‘lgan yozuvlarni filter qiling.\n\ndf = spark.createDataFrame([(\"Ali\", 25), (\"Vali\", 30)], [\"name\", \"age\"])\n\ndf.filter(df['age']>25).show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T06:56:39.090412Z","iopub.execute_input":"2025-05-13T06:56:39.090905Z","iopub.status.idle":"2025-05-13T06:56:39.906102Z","shell.execute_reply.started":"2025-05-13T06:56:39.090867Z","shell.execute_reply":"2025-05-13T06:56:39.900722Z"}},"outputs":[{"name":"stdout","text":"+----+---+\n|name|age|\n+----+---+\n|Vali| 30|\n+----+---+\n\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Har bir ismga \"Mr.\" prefixini qo‘shib chiqaring\nfrom pyspark.sql.functions import concat, lit\n\ndf = spark.createDataFrame([(\"Ali\",), (\"Vali\",)], [\"name\"])\n\ndf = df.withColumn(\"name\", concat(lit(\"Mr. \"), df[\"name\"]))\n\ndf.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T06:56:39.907626Z","iopub.execute_input":"2025-05-13T06:56:39.908038Z","iopub.status.idle":"2025-05-13T06:56:40.599225Z","shell.execute_reply.started":"2025-05-13T06:56:39.908002Z","shell.execute_reply":"2025-05-13T06:56:40.598224Z"}},"outputs":[{"name":"stdout","text":"+--------+\n|    name|\n+--------+\n| Mr. Ali|\n|Mr. Vali|\n+--------+\n\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# `age` ustuniga 5 qo‘shing va yangi ustun sifatida yarating.\n\ndf = spark.createDataFrame([(\"Ali\", 25), (\"Vali\", 30)], [\"name\", \"age\"])\n\ndf=df.withColumn('algo', df['age']+5)\n\ndf.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T06:56:40.600203Z","iopub.execute_input":"2025-05-13T06:56:40.600559Z","iopub.status.idle":"2025-05-13T06:56:41.336220Z","shell.execute_reply.started":"2025-05-13T06:56:40.600529Z","shell.execute_reply":"2025-05-13T06:56:41.332959Z"}},"outputs":[{"name":"stdout","text":"+----+---+----+\n|name|age|algo|\n+----+---+----+\n| Ali| 25|  30|\n|Vali| 30|  35|\n+----+---+----+\n\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# DataFrame’da qancha satr borligini hisoblang.\n\ndf = spark.createDataFrame([(\"Ali\", 25), (\"Vali\", 30), (\"Hasan\", 22)], [\"name\", \"age\"])\n\ndf.count()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T06:56:41.337469Z","iopub.execute_input":"2025-05-13T06:56:41.338165Z","iopub.status.idle":"2025-05-13T06:56:42.539938Z","shell.execute_reply.started":"2025-05-13T06:56:41.338132Z","shell.execute_reply":"2025-05-13T06:56:42.539078Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"3"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# Barcha yoshlarning o‘rtacha qiymatini hisoblang.\nfrom pyspark.sql.functions import avg, col\ndf = spark.createDataFrame([(\"Ali\", 25), (\"Vali\", 30), (\"Hasan\", 22)], [\"name\", \"age\"])\ndf.select(avg(col(\"age\"))).show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T06:56:42.540715Z","iopub.execute_input":"2025-05-13T06:56:42.541043Z","iopub.status.idle":"2025-05-13T06:56:43.484302Z","shell.execute_reply.started":"2025-05-13T06:56:42.541008Z","shell.execute_reply":"2025-05-13T06:56:43.483419Z"}},"outputs":[{"name":"stdout","text":"+------------------+\n|          avg(age)|\n+------------------+\n|25.666666666666668|\n+------------------+\n\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Ismlarni alifbo tartibida sort qiling.\ndf = spark.createDataFrame([(\"Vali\",), (\"Ali\",), (\"Hasan\",)], [\"name\"])\n\ndf.sort('name').show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T06:56:43.487878Z","iopub.execute_input":"2025-05-13T06:56:43.488851Z","iopub.status.idle":"2025-05-13T06:56:44.190236Z","shell.execute_reply.started":"2025-05-13T06:56:43.488816Z","shell.execute_reply":"2025-05-13T06:56:44.188917Z"}},"outputs":[{"name":"stdout","text":"+-----+\n| name|\n+-----+\n|  Ali|\n|Hasan|\n| Vali|\n+-----+\n\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# DataFrame’ga gender ustunini \"male\" deb qo‘shing.\nfrom pyspark.sql.functions import lit\ndf = spark.createDataFrame([(\"Ali\", 25), (\"Vali\", 30)], [\"name\", \"age\"])\n\ndf.withColumn('gender', lit('male'))\n\ndf.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T06:56:44.191212Z","iopub.execute_input":"2025-05-13T06:56:44.191487Z","iopub.status.idle":"2025-05-13T06:56:44.777357Z","shell.execute_reply.started":"2025-05-13T06:56:44.191465Z","shell.execute_reply":"2025-05-13T06:56:44.776223Z"}},"outputs":[{"name":"stdout","text":"+----+---+\n|name|age|\n+----+---+\n| Ali| 25|\n|Vali| 30|\n+----+---+\n\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Ismlarning uzunligini hisoblab yangi ustun yarating.\nfrom pyspark.sql.functions import length\n\ndf = spark.createDataFrame([(\"Ali\",), (\"Vali\",)], [\"name\"])\n\ndf = df.withColumn('length', length(\"name\"))\n\ndf.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T06:56:44.779966Z","iopub.execute_input":"2025-05-13T06:56:44.780295Z","iopub.status.idle":"2025-05-13T06:56:45.407135Z","shell.execute_reply.started":"2025-05-13T06:56:44.780265Z","shell.execute_reply":"2025-05-13T06:56:45.406243Z"}},"outputs":[{"name":"stdout","text":"+----+------+\n|name|length|\n+----+------+\n| Ali|     3|\n|Vali|     4|\n+----+------+\n\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Yoshni 10 ga bo‘lingan qiymatini hisoblab ustun yarating.\n\ndf = spark.createDataFrame([(\"Ali\", 25), (\"Vali\", 30)], [\"name\", \"age\"])\n\ndf=df.withColumn('algo', df['age']/10)\n\ndf.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T06:56:45.408849Z","iopub.execute_input":"2025-05-13T06:56:45.409165Z","iopub.status.idle":"2025-05-13T06:56:46.002961Z","shell.execute_reply.started":"2025-05-13T06:56:45.409138Z","shell.execute_reply":"2025-05-13T06:56:46.002037Z"}},"outputs":[{"name":"stdout","text":"+----+---+----+\n|name|age|algo|\n+----+---+----+\n| Ali| 25| 2.5|\n|Vali| 30| 3.0|\n+----+---+----+\n\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Har bir department bo‘yicha o‘rtacha maoshni toping.\n\ndf = spark.createDataFrame([(\"IT\", 1000), (\"HR\", 800), (\"IT\", 1200)], [\"department\", \"salary\"])\n\ndf.groupBy('department').agg({'salary':'avg'}).show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T06:56:46.003723Z","iopub.execute_input":"2025-05-13T06:56:46.004024Z","iopub.status.idle":"2025-05-13T06:56:47.064408Z","shell.execute_reply.started":"2025-05-13T06:56:46.003998Z","shell.execute_reply":"2025-05-13T06:56:47.063239Z"}},"outputs":[{"name":"stdout","text":"+----------+-----------+\n|department|avg(salary)|\n+----------+-----------+\n|        IT|     1100.0|\n|        HR|      800.0|\n+----------+-----------+\n\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Har bir department bo‘yicha ishchilar sonini hisoblang.\n\ndf = spark.createDataFrame([(\"IT\",), (\"HR\",), (\"IT\",)], [\"department\"])\n\ndf.groupBy('department').count().show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T06:56:47.067179Z","iopub.execute_input":"2025-05-13T06:56:47.067567Z","iopub.status.idle":"2025-05-13T06:56:47.796405Z","shell.execute_reply.started":"2025-05-13T06:56:47.067534Z","shell.execute_reply":"2025-05-13T06:56:47.795391Z"}},"outputs":[{"name":"stdout","text":"+----------+-----+\n|department|count|\n+----------+-----+\n|        IT|    2|\n|        HR|    1|\n+----------+-----+\n\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Eng yuqori maoshli departmentni toping.\nfrom pyspark.sql.functions import max\ndf = spark.createDataFrame([(\"IT\", 1000), (\"HR\", 2000), (\"Sales\", 1500)], [\"department\", \"salary\"])\n\n# 1-usul \n# df.orderBy(\"salary\", ascending=False).limit(1).show()\n\n# 2-usul\nmax_salary = df.agg(max(\"salary\").alias(\"max_salary\")).collect()[0][\"max_salary\"]\ndf.filter(df.salary == max_salary).show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T06:56:47.797119Z","iopub.execute_input":"2025-05-13T06:56:47.797427Z","iopub.status.idle":"2025-05-13T06:56:49.023203Z","shell.execute_reply.started":"2025-05-13T06:56:47.797401Z","shell.execute_reply":"2025-05-13T06:56:49.022207Z"}},"outputs":[{"name":"stdout","text":"+----------+------+\n|department|salary|\n+----------+------+\n|        HR|  2000|\n+----------+------+\n\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# gender bo‘yicha salary summasini toping.\n\ndf = spark.createDataFrame([(\"male\", 1000), (\"female\", 1200), (\"male\", 800)], [\"gender\", \"salary\"])\n\ndf.groupBy('gender').agg({'salary': 'sum'}).show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T06:56:49.024003Z","iopub.execute_input":"2025-05-13T06:56:49.024314Z","iopub.status.idle":"2025-05-13T06:56:49.679480Z","shell.execute_reply.started":"2025-05-13T06:56:49.024289Z","shell.execute_reply":"2025-05-13T06:56:49.677196Z"}},"outputs":[{"name":"stdout","text":"+------+-----------+\n|gender|sum(salary)|\n+------+-----------+\n|  male|       1800|\n|female|       1200|\n+------+-----------+\n\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Har bir cityda eng katta yoshi bor foydalanuvchini toping.\n\ndf = spark.createDataFrame([(\"Tashkent\", \"Ali\", 25), (\"Tashkent\", \"Vali\", 35), (\"Bukhara\", \"Sami\", 30)], [\"city\", \"name\", \"age\"])\n\ndf_maxs=df.groupBy('city').agg({'age': 'max'}).show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T06:56:49.680353Z","iopub.execute_input":"2025-05-13T06:56:49.680721Z","iopub.status.idle":"2025-05-13T06:56:50.395041Z","shell.execute_reply.started":"2025-05-13T06:56:49.680691Z","shell.execute_reply":"2025-05-13T06:56:50.390320Z"}},"outputs":[{"name":"stdout","text":"+--------+--------+\n|    city|max(age)|\n+--------+--------+\n|Tashkent|      35|\n| Bukhara|      30|\n+--------+--------+\n\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Null qiymatli satrlarni chiqarib tashlang.\n\ndf = spark.createDataFrame([(\"Ali\", 25), (None, 30), (\"Vali\", None)], [\"name\", \"age\"])\n\ndf.dropna().show()\ndf.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T06:56:50.397477Z","iopub.execute_input":"2025-05-13T06:56:50.397865Z","iopub.status.idle":"2025-05-13T06:56:51.304998Z","shell.execute_reply.started":"2025-05-13T06:56:50.397789Z","shell.execute_reply":"2025-05-13T06:56:51.303353Z"}},"outputs":[{"name":"stdout","text":"+----+---+\n|name|age|\n+----+---+\n| Ali| 25|\n+----+---+\n\n+----+----+\n|name| age|\n+----+----+\n| Ali|  25|\n|NULL|  30|\n|Vali|NULL|\n+----+----+\n\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# age bo‘yicha minimal va maksimal qiymatni toping.\nfrom pyspark.sql.functions import max, min\ndf = spark.createDataFrame([(\"Ali\", 25), (\"Vali\", 30), (\"Hasan\", 20)], [\"name\", \"age\"])\n\ndf.select(max('age')).show()\ndf.select(min('age')).show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T06:56:51.306186Z","iopub.execute_input":"2025-05-13T06:56:51.306810Z","iopub.status.idle":"2025-05-13T06:56:52.376126Z","shell.execute_reply.started":"2025-05-13T06:56:51.306770Z","shell.execute_reply":"2025-05-13T06:56:52.375118Z"}},"outputs":[{"name":"stdout","text":"+--------+\n|max(age)|\n+--------+\n|      30|\n+--------+\n\n+--------+\n|min(age)|\n+--------+\n|      20|\n+--------+\n\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# department bo‘yicha salaryning o‘rtacha, min va max qiymatlarini toping.\ndf = spark.createDataFrame([(\"IT\", 1000), (\"HR\", 2000), (\"IT\", 1500)], [\"department\", \"salary\"])\n\ndf.groupBy('department').agg({'salary':'min'}).show()\ndf.groupBy('department').agg({'salary':'min'}).show()\ndf.groupBy('department').agg({'salary':'avg'}).show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T06:56:52.377628Z","iopub.execute_input":"2025-05-13T06:56:52.377933Z","iopub.status.idle":"2025-05-13T06:56:54.048809Z","shell.execute_reply.started":"2025-05-13T06:56:52.377905Z","shell.execute_reply":"2025-05-13T06:56:54.047564Z"}},"outputs":[{"name":"stdout","text":"+----------+-----------+\n|department|min(salary)|\n+----------+-----------+\n|        IT|       1000|\n|        HR|       2000|\n+----------+-----------+\n\n+----------+-----------+\n|department|min(salary)|\n+----------+-----------+\n|        IT|       1000|\n|        HR|       2000|\n+----------+-----------+\n\n+----------+-----------+\n|department|avg(salary)|\n+----------+-----------+\n|        IT|     1250.0|\n|        HR|     2000.0|\n+----------+-----------+\n\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Har bir department bo‘yicha eng so‘nggi qo‘shilgan xodimni toping (join_date).\n\ndf = spark.createDataFrame([(\"IT\", \"Ali\", \"2023-01-01\"), (\"IT\", \"Vali\", \"2024-01-01\")], [\"department\", \"name\", \"join_date\"])\ndf.withColumn('join_date', df['join_date'].cast('date'))\ndf.groupBy('department').agg({'join_date':'max'}).show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T06:56:54.050461Z","iopub.execute_input":"2025-05-13T06:56:54.051069Z","iopub.status.idle":"2025-05-13T06:56:54.842082Z","shell.execute_reply.started":"2025-05-13T06:56:54.050868Z","shell.execute_reply":"2025-05-13T06:56:54.841224Z"}},"outputs":[{"name":"stdout","text":"+----------+--------------+\n|department|max(join_date)|\n+----------+--------------+\n|        IT|    2024-01-01|\n+----------+--------------+\n\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# Har bir foydalanuvchining salary darajasi above average yoki below average ekanligini belgilang.\nfrom pyspark.sql.functions import avg, col, when\n\ndf = spark.createDataFrame([(\"Ali\", 1000), (\"Vali\", 2000), (\"Sami\", 1500)], [\"name\", \"salary\"])\n\navg_salary = df.select(avg(\"salary\")).collect()[0][0]\n\ndf = df.withColumn(\"level\", when(col(\"salary\") >= avg_salary, \"above average\").otherwise(\"below average\"))\n\ndf.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T07:08:38.840530Z","iopub.execute_input":"2025-05-13T07:08:38.840821Z","iopub.status.idle":"2025-05-13T07:08:39.574679Z","shell.execute_reply.started":"2025-05-13T07:08:38.840800Z","shell.execute_reply":"2025-05-13T07:08:39.573599Z"}},"outputs":[{"name":"stdout","text":"+----+------+-------------+\n|name|salary|        level|\n+----+------+-------------+\n| Ali|  1000|below average|\n|Vali|  2000|above average|\n|Sami|  1500|above average|\n+----+------+-------------+\n\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"# Ikkita DataFrame’ni id bo‘yicha birlashtiring.\ndf1 = spark.createDataFrame([(1, \"Ali\"), (2, \"Vali\")], [\"id\", \"name\"])\ndf2 = spark.createDataFrame([(1, \"IT\"), (2, \"HR\")], [\"id\", \"department\"])\n\ndf=df1.join(df2, df1['id']==df2['id'], 'inner')\n\ndf.select(df1['id'], 'name', 'department').show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T07:13:04.548007Z","iopub.execute_input":"2025-05-13T07:13:04.548284Z","iopub.status.idle":"2025-05-13T07:13:05.244623Z","shell.execute_reply.started":"2025-05-13T07:13:04.548267Z","shell.execute_reply":"2025-05-13T07:13:05.243860Z"}},"outputs":[{"name":"stdout","text":"+---+----+----------+\n| id|name|department|\n+---+----+----------+\n|  1| Ali|        IT|\n|  2|Vali|        HR|\n+---+----+----------+\n\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"# Chap join orqali barcha foydalanuvchilar va ularning bo‘limlarini ko‘rsating.\n\ndf=df1.join(df2, df1['id']==df2['id'], 'left')\n\ndf.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T07:24:07.515937Z","iopub.execute_input":"2025-05-13T07:24:07.516244Z","iopub.status.idle":"2025-05-13T07:24:08.290364Z","shell.execute_reply.started":"2025-05-13T07:24:07.516223Z","shell.execute_reply":"2025-05-13T07:24:08.288424Z"}},"outputs":[{"name":"stdout","text":"+---+----+---+----------+\n| id|name| id|department|\n+---+----+---+----------+\n|  1| Ali|  1|        IT|\n|  2|Vali|  2|        HR|\n+---+----+---+----------+\n\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"# To‘liq outer join orqali barcha ma’lumotlarni qo‘shing.\n\ndf=df1.join(df2, df1['id']==df2['id'], 'outer')\n\ndf.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T07:25:15.319897Z","iopub.execute_input":"2025-05-13T07:25:15.320227Z","iopub.status.idle":"2025-05-13T07:25:16.050504Z","shell.execute_reply.started":"2025-05-13T07:25:15.320204Z","shell.execute_reply":"2025-05-13T07:25:16.049480Z"}},"outputs":[{"name":"stdout","text":"+---+----+---+----------+\n| id|name| id|department|\n+---+----+---+----------+\n|  1| Ali|  1|        IT|\n|  2|Vali|  2|        HR|\n+---+----+---+----------+\n\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"# Join qiling, lekin faqat mos kelmaganlarini ko‘rsating (anti join).\n\ndf=df1.join(df2, df1['id']==df2['id'], 'left_anti')\n\ndf.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T07:27:18.524990Z","iopub.execute_input":"2025-05-13T07:27:18.525293Z","iopub.status.idle":"2025-05-13T07:27:19.313907Z","shell.execute_reply.started":"2025-05-13T07:27:18.525272Z","shell.execute_reply":"2025-05-13T07:27:19.312831Z"}},"outputs":[{"name":"stdout","text":"+---+----+\n| id|name|\n+---+----+\n+---+----+\n\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"# Ikkita jadvalni birlashtiring va fullName ustunini yarating.\n\ndf1 = spark.createDataFrame([(1, \"Ali\")], [\"id\", \"firstName\"])\ndf2 = spark.createDataFrame([(1, \"Valiyev\")], [\"id\", \"lastName\"])\n\ndf=df1.join(df2, df1['id']==df2['id'], how='inner')\n\ndf=df.withColumn('FullName', df['firstName']+df['lastName'])\n\ndf.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T07:30:11.757915Z","iopub.execute_input":"2025-05-13T07:30:11.758187Z","iopub.status.idle":"2025-05-13T07:30:12.690341Z","shell.execute_reply.started":"2025-05-13T07:30:11.758169Z","shell.execute_reply":"2025-05-13T07:30:12.689269Z"}},"outputs":[{"name":"stdout","text":"+---+---------+---+--------+--------+\n| id|firstName| id|lastName|FullName|\n+---+---------+---+--------+--------+\n|  1|      Ali|  1| Valiyev|    NULL|\n+---+---------+---+--------+--------+\n\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"# user_id bo‘yicha orders va users ni join qiling.\n\nusers = spark.createDataFrame([(1, \"Ali\"), (2, \"Vali\")], [\"user_id\", \"name\"])\norders = spark.createDataFrame([(1, 100), (1, 200), (2, 150)], [\"user_id\", \"amount\"])\n\ndf=users.join(orders, users['user_id']==orders['user_id'], 'inner')\n\ndf.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T07:43:47.941025Z","iopub.execute_input":"2025-05-13T07:43:47.941476Z","iopub.status.idle":"2025-05-13T07:43:48.845530Z","shell.execute_reply.started":"2025-05-13T07:43:47.941447Z","shell.execute_reply":"2025-05-13T07:43:48.844675Z"}},"outputs":[{"name":"stdout","text":"+-------+----+-------+------+\n|user_id|name|user_id|amount|\n+-------+----+-------+------+\n|      1| Ali|      1|   100|\n|      1| Ali|      1|   200|\n|      2|Vali|      2|   150|\n+-------+----+-------+------+\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"# Join qiling va har bir foydalanuvchining umumiy buyurtma miqdorini hisoblang.\nfrom pyspark.sql.functions import sum\ndf = users.join(orders, on=\"user_id\", how=\"inner\")\ndf.groupBy(\"user_id\", \"name\").agg(sum(\"amount\").alias(\"total_amount\")).show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T07:44:31.289884Z","iopub.execute_input":"2025-05-13T07:44:31.290171Z","iopub.status.idle":"2025-05-13T07:44:32.172692Z","shell.execute_reply.started":"2025-05-13T07:44:31.290152Z","shell.execute_reply":"2025-05-13T07:44:32.170978Z"}},"outputs":[{"name":"stdout","text":"+-------+----+------------+\n|user_id|name|total_amount|\n+-------+----+------------+\n|      1| Ali|         300|\n|      2|Vali|         150|\n+-------+----+------------+\n\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"# users jadvalidan hech qanday buyurtma qilmagan foydalanuvchilarni toping.\n\ndf=users.join(orders, users['user_id']==orders['user_id'], 'left_anti').show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Har bir department ichida salary bo‘yicha rank yarating.\n\ndf = spark.createDataFrame([(\"IT\", \"Ali\", 1000), (\"IT\", \"Vali\", 1200), (\"HR\", \"Sami\", 1100)], [\"dept\", \"name\", \"salary\"])\n\ndf=df.groupBy('dept').agg({'salary': 'sum'})\n\ndf.sort('sum(salary)').show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T08:20:30.007020Z","iopub.execute_input":"2025-05-13T08:20:30.007331Z","iopub.status.idle":"2025-05-13T08:20:30.827979Z","shell.execute_reply.started":"2025-05-13T08:20:30.007310Z","shell.execute_reply":"2025-05-13T08:20:30.826123Z"}},"outputs":[{"name":"stdout","text":"+----+-----------+\n|dept|sum(salary)|\n+----+-----------+\n|  HR|       1100|\n|  IT|       2200|\n+----+-----------+\n\n","output_type":"stream"}],"execution_count":70},{"cell_type":"code","source":"# Rolling average hisoblang oxirgi 3 satr uchun. (1-usul)\n\ndf = spark.createDataFrame([(1, 100), (2, 200), (3, 300), (4, 400)], [\"day\", \"value\"])\n\ndf=df.filter(df['day']>1).agg({'value': 'avg'})\n\ndf.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T08:28:06.603908Z","iopub.execute_input":"2025-05-13T08:28:06.604221Z","iopub.status.idle":"2025-05-13T08:28:07.174287Z","shell.execute_reply.started":"2025-05-13T08:28:06.604197Z","shell.execute_reply":"2025-05-13T08:28:07.172976Z"}},"outputs":[{"name":"stdout","text":"+----------+\n|avg(value)|\n+----------+\n|     300.0|\n+----------+\n\n","output_type":"stream"}],"execution_count":73},{"cell_type":"code","source":"# Rolling average hisoblang oxirgi 3 satr uchun. (1-usul)\nfrom pyspark.sql.functions import avg\nfrom pyspark.sql.window import Window\n\ndf = spark.createDataFrame([(1, 100), (2, 200), (3, 300), (4, 400)], [\"day\", \"value\"])\n\nn=3\n\nwindowSpec = Window.orderBy(\"day\").rowsBetween(-n + 1, 0)\n\ndf = df.withColumn(\"rolling_avg\", avg(\"value\").over(windowSpec))\n\ndf.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T08:31:24.180498Z","iopub.execute_input":"2025-05-13T08:31:24.180801Z","iopub.status.idle":"2025-05-13T08:31:24.910427Z","shell.execute_reply.started":"2025-05-13T08:31:24.180778Z","shell.execute_reply":"2025-05-13T08:31:24.909449Z"}},"outputs":[{"name":"stderr","text":"25/05/13 08:31:24 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n25/05/13 08:31:24 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n25/05/13 08:31:24 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n25/05/13 08:31:24 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n25/05/13 08:31:24 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n","output_type":"stream"},{"name":"stdout","text":"+---+-----+-----------+\n|day|value|rolling_avg|\n+---+-----+-----------+\n|  1|  100|      100.0|\n|  2|  200|      150.0|\n|  3|  300|      200.0|\n|  4|  400|      300.0|\n+---+-----+-----------+\n\n","output_type":"stream"}],"execution_count":77},{"cell_type":"code","source":"# LAG funksiyasi yordamida avvalgi satrdagi qiymatni chiqarish.\nfrom pyspark.sql.functions import lag\nfrom pyspark.sql.window import Window\n\nwindowSpec = Window.orderBy(\"day\")\n\ndf = df.withColumn(\"prev_value\", lag(\"value\", 1).over(windowSpec))\n\ndf.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T08:37:39.548297Z","iopub.execute_input":"2025-05-13T08:37:39.549180Z","iopub.status.idle":"2025-05-13T08:37:40.161538Z","shell.execute_reply.started":"2025-05-13T08:37:39.549150Z","shell.execute_reply":"2025-05-13T08:37:40.160330Z"}},"outputs":[{"name":"stderr","text":"25/05/13 08:37:39 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n25/05/13 08:37:39 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n25/05/13 08:37:39 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n","output_type":"stream"},{"name":"stdout","text":"+---+-----+-----------+----------+\n|day|value|rolling_avg|prev_value|\n+---+-----+-----------+----------+\n|  1|  100|      100.0|      NULL|\n|  2|  200|      150.0|       100|\n|  3|  300|      200.0|       200|\n|  4|  400|      300.0|       300|\n+---+-----+-----------+----------+\n\n","output_type":"stream"},{"name":"stderr","text":"25/05/13 08:37:39 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n25/05/13 08:37:39 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n","output_type":"stream"}],"execution_count":81},{"cell_type":"code","source":"# LEAD funksiyasi yordamida keyingi qiymatni ko‘rsatish.\nfrom pyspark.sql.functions import lead\n\nwindowSpec = Window.orderBy(\"day\")\n\ndf = df.withColumn(\"prev_value\", lead(\"value\", 1).over(windowSpec))\n\ndf.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T08:40:36.359813Z","iopub.execute_input":"2025-05-13T08:40:36.360100Z","iopub.status.idle":"2025-05-13T08:40:36.970146Z","shell.execute_reply.started":"2025-05-13T08:40:36.360080Z","shell.execute_reply":"2025-05-13T08:40:36.969013Z"}},"outputs":[{"name":"stderr","text":"25/05/13 08:40:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n25/05/13 08:40:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n25/05/13 08:40:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n","output_type":"stream"},{"name":"stdout","text":"+---+-----+-----------+----------+\n|day|value|rolling_avg|prev_value|\n+---+-----+-----------+----------+\n|  1|  100|      100.0|       200|\n|  2|  200|      150.0|       300|\n|  3|  300|      200.0|       400|\n|  4|  400|      300.0|      NULL|\n+---+-----+-----------+----------+\n\n","output_type":"stream"},{"name":"stderr","text":"25/05/13 08:40:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n25/05/13 08:40:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n","output_type":"stream"}],"execution_count":85},{"cell_type":"code","source":"# Foydalanuvchining umumiy buyurtmalarini hisoblash (partition by).\n\ndf = spark.createDataFrame([(\"Ali\", 100), (\"Ali\", 200), (\"Vali\", 300)], [\"name\", \"amount\"])\n\nwindowSpec = Window.partitionBy(\"name\")\ndf = df.withColumn(\"total_amount\", sum(\"amount\").over(windowSpec))\n\ndf.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Row number har bir foydalanuvchining buyurtmalari bo‘yicha yarating.\nfrom pyspark.sql.functions import row_number\n\ndf = spark.createDataFrame([(\"Ali\", 100), (\"Ali\", 200), (\"Vali\", 300)], [\"name\", \"amount\"])\n\n# 1-usul\n# df.groupBy('name').agg({'amount': 'sum'}).show()\n\n# 2-usul\n\nwindowSpec = Window.partitionBy(\"name\").orderBy(\"amount\")\n\n# Row number ustunini qo‘shish\ndf = df.withColumn(\"row_num\", row_number().over(windowSpec))\n\ndf.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T09:16:08.720927Z","iopub.execute_input":"2025-05-13T09:16:08.721283Z","iopub.status.idle":"2025-05-13T09:16:09.455091Z","shell.execute_reply.started":"2025-05-13T09:16:08.721255Z","shell.execute_reply":"2025-05-13T09:16:09.454006Z"}},"outputs":[{"name":"stdout","text":"+----+------+-------+\n|name|amount|row_num|\n+----+------+-------+\n| Ali|   100|      1|\n| Ali|   200|      2|\n|Vali|   300|      1|\n+----+------+-------+\n\n","output_type":"stream"}],"execution_count":96},{"cell_type":"code","source":"# Har bir bo‘limda eng ko‘p maosh olgan xodimni tanlang.\n\ndf = spark.createDataFrame([(\"IT\", \"Ali\", 1000), (\"IT\", \"Vali\", 1200), (\"HR\", \"Sami\", 1100)], [\"dept\", \"name\", \"salary\"])\n\nsort=Window.partitionBy('dept')\n\ndf=df.withColumn('max', max('salary').over(sort))\n\ndf.filter(df['salary']==df['max']).show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T09:23:35.006907Z","iopub.execute_input":"2025-05-13T09:23:35.007203Z","iopub.status.idle":"2025-05-13T09:23:35.704605Z","shell.execute_reply.started":"2025-05-13T09:23:35.007182Z","shell.execute_reply":"2025-05-13T09:23:35.703537Z"}},"outputs":[{"name":"stdout","text":"+----+----+------+----+\n|dept|name|salary| max|\n+----+----+------+----+\n|  HR|Sami|  1100|1100|\n|  IT|Vali|  1200|1200|\n+----+----+------+----+\n\n","output_type":"stream"}],"execution_count":101},{"cell_type":"code","source":"# Ish boshlagan kundan boshlab umumiy daromadni hisoblang.\nfrom pyspark.sql.functions import sum\n\ndf = spark.createDataFrame([(\"Ali\", \"2024-01-01\", 100), (\"Ali\", \"2024-01-02\", 150)], [\"name\", \"date\", \"amount\"])\n\nsort=Window.partitionBy('name')\n\ndf=df.withColumn('sum', sum('amount').over(sort))\n\ndf.first()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T09:32:35.315507Z","iopub.execute_input":"2025-05-13T09:32:35.315826Z","iopub.status.idle":"2025-05-13T09:32:35.791479Z","shell.execute_reply.started":"2025-05-13T09:32:35.315802Z","shell.execute_reply":"2025-05-13T09:32:35.790271Z"}},"outputs":[{"execution_count":106,"output_type":"execute_result","data":{"text/plain":"Row(name='Ali', date='2024-01-01', amount=100, sum=250)"},"metadata":{}}],"execution_count":106},{"cell_type":"code","source":"# Nested struktura (StructType) bilan ishlang va fieldni ajrating.\nfrom pyspark.sql.functions import col\n\ndf = spark.createDataFrame([((\"Ali\", 25),)], [\"person\"])\n\ndf2 = df.select(\n    col(\"person._1\").alias(\"name\"),\n    col(\"person._2\").alias(\"age\")\n)\n\ndf2.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T09:40:30.854203Z","iopub.execute_input":"2025-05-13T09:40:30.854764Z","iopub.status.idle":"2025-05-13T09:40:31.451198Z","shell.execute_reply.started":"2025-05-13T09:40:30.854726Z","shell.execute_reply":"2025-05-13T09:40:31.449987Z"}},"outputs":[{"name":"stdout","text":"+----+---+\n|name|age|\n+----+---+\n| Ali| 25|\n+----+---+\n\n","output_type":"stream"}],"execution_count":112},{"cell_type":"code","source":"# Array ustunidan elementlarni ajrating.\nfrom pyspark.sql.functions import col, explode\n\ntry:\n    df = spark.createDataFrame([([\"Ali\", \"Vali\"],)], [\"names\"])\n\n    df2=df.select(\n        col('names')[0].alias('name1'),\n        col('names')[1].alias('name2')\n    )\n    \n    df2.show()\nexcept Exception as e:\n    print(e)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T09:48:13.337862Z","iopub.execute_input":"2025-05-13T09:48:13.338168Z","iopub.status.idle":"2025-05-13T09:48:13.887013Z","shell.execute_reply.started":"2025-05-13T09:48:13.338149Z","shell.execute_reply":"2025-05-13T09:48:13.885905Z"}},"outputs":[{"name":"stdout","text":"+-----+-----+\n|name1|name2|\n+-----+-----+\n|  Ali| Vali|\n+-----+-----+\n\n","output_type":"stream"}],"execution_count":120},{"cell_type":"code","source":"# Explode funksiyasi orqali array’ni to‘g‘rilang.\n\ndf2=df.select(explode(df['names']).alias('name'))\n\ndf2.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T09:49:08.670301Z","iopub.execute_input":"2025-05-13T09:49:08.670706Z","iopub.status.idle":"2025-05-13T09:49:09.153542Z","shell.execute_reply.started":"2025-05-13T09:49:08.670680Z","shell.execute_reply":"2025-05-13T09:49:09.152562Z"}},"outputs":[{"name":"stdout","text":"+----+\n|name|\n+----+\n| Ali|\n|Vali|\n+----+\n\n","output_type":"stream"}],"execution_count":122},{"cell_type":"code","source":"# JSON ustunini parse qiling.\nfrom pyspark.sql.functions import json_tuple\n\ndf = spark.createDataFrame([('{\"name\": \"Ali\", \"age\": 25}',)], [\"json_col\"])\n\ndf2 = df.select(\n    json_tuple(col(\"json_col\"), \"name\", \"age\").alias(\"name\", \"age\")\n)\n\ndf2.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T09:55:06.409944Z","iopub.execute_input":"2025-05-13T09:55:06.410249Z","iopub.status.idle":"2025-05-13T09:55:07.095201Z","shell.execute_reply.started":"2025-05-13T09:55:06.410227Z","shell.execute_reply":"2025-05-13T09:55:07.093950Z"}},"outputs":[{"name":"stdout","text":"+----+---+\n|name|age|\n+----+---+\n| Ali| 25|\n+----+---+\n\n","output_type":"stream"}],"execution_count":127},{"cell_type":"code","source":"from pyspark.sql import functions as F\n\n# DataFrame yaratish\ndf = spark.createDataFrame([(\"2024-01-01\",)], [\"date\"])\n\n# Date ustunini Date turiga o'zgartirish\ndf = df.withColumn(\"date\", df[\"date\"].cast(\"date\"))\n\n# Yil va oy ajratish\ndf = df.withColumn(\"year\", F.year(df[\"date\"])) \\\n       .withColumn(\"month\", F.month(df[\"date\"]))\n\n# Natijani ko‘rish\ndf.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T10:20:26.812351Z","iopub.execute_input":"2025-05-13T10:20:26.812672Z","iopub.status.idle":"2025-05-13T10:20:27.380336Z","shell.execute_reply.started":"2025-05-13T10:20:26.812651Z","shell.execute_reply":"2025-05-13T10:20:27.376846Z"}},"outputs":[{"name":"stdout","text":"+----------+----+-----+\n|      date|year|month|\n+----------+----+-----+\n|2024-01-01|2024|    1|\n+----------+----+-----+\n\n","output_type":"stream"}],"execution_count":137}]}